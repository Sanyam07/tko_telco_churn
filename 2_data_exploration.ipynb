{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the data\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import Row, StructField, StructType, StringType, IntegerType\n",
    "\n",
    "s3_bucket = os.environ.get('S3_BUCKET', \"s3a://ml-field/demo/wine/\")\n",
    "s3_bucket_region = os.environ.get('S3_BUCKET_REGION', \"us-west-2\")\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"Import Wine Table\")\\\n",
    "    .config(\"spark.yarn.access.hadoopFileSystems\",s3_bucket)\\\n",
    "    .config(\"spark.hadoop.fs.s3a.s3guard.ddb.region\", s3_bucket_region)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "wine_data_raw = spark.sql(\"SELECT * FROM `default`.`wine`\")\n",
    "wine_data_raw.show(3) \n",
    "\n",
    "# ### Basic DataFrame operations\n",
    "# Dataframes essentially allow you to express sql-like statements. \n",
    "# We can filter, count, and so on. \n",
    "# Documentation - (http://spark.apache.org/docs/latest/sql-programming-guide.html#dataframe-operations)\n",
    "\n",
    "\"number of lines in dataset : {:d}\".format(wine_data_raw.count())\n",
    "\n",
    "# ### Spark SQL - manipulate data as if it was a table \n",
    "wine_data_raw.createOrReplaceTempView(\"wine\")\n",
    "spark.sql(\"select distinct(Quality), count(*) from wine GROUP BY Quality\").show()\n",
    "\n",
    "\n",
    "# ### Remove invalid data\n",
    "wine_data = wine_data_raw.filter(wine_data_raw.Quality != \"1\")\n",
    "total_wines = wine_data.count()\n",
    "good_wines = wine_data.filter(wine_data.Quality == 'Excellent').count()\n",
    "poor_wines = wine_data.filter(wine_data.Quality == 'Poor').count()\n",
    "\n",
    "\"Wines total: {}, Good : {}, Poor : {}\".format(total_wines,good_wines,poor_wines )\n",
    "\n",
    "\n",
    "# # 2. Data visualisation ( using mathplotlib and Seaborn)\n",
    "# ## Feature Visualization\n",
    "# \n",
    "# The data vizualization workflow for large data sets is usually:\n",
    "# \n",
    "# * Sample data so it fits in memory on a single machine.\n",
    "# * Examine single variable distributions.\n",
    "# * Examine joint distributions and correlations.\n",
    "# * Look for other types of relationships.\n",
    "# \n",
    "# [DataFrame#sample() documentation](http://people.apache.org/~pwendell/spark-releases/spark-1.5.0-rc1-docs/api/python/pyspark.sql.html#pyspark.sql.DataFrame.sample)\n",
    "\n",
    "# ### Note: toPandas() => brings data localy !!!\n",
    "sample_data = wine_data.sample(False, 0.5, 83).toPandas()\n",
    "sample_data.transpose().head(21)\n",
    "\n",
    "spark.stop()\n",
    "\n",
    "\n",
    "# ## Feature Distributions\n",
    "# \n",
    "# We want to examine the distribution of our features, so start with them one at a time.\n",
    "# \n",
    "# Seaborn has a standard function called [dist()](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.distplot.html#seaborn.distplot) that allows us to easily examine the distribution of a column of a pandas dataframe or a numpy array.\n",
    "\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "sb.distplot(sample_data['Alcohol'], kde=False)\n",
    "\n",
    "# We can examine feature differences in the distribution of our features when we condition (split) our data.\n",
    "# \n",
    "# [BoxPlot docs](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.boxplot.html)\n",
    "\n",
    "\n",
    "sb.boxplot(x=\"Quality\", y=\"Alcohol\", data=sample_data)\n",
    "\n",
    "# ## Joint Distributions\n",
    "# \n",
    "# Looking at joint distributions of data can also tell us a lot, particularly about redundant features. [Seaborn's PairPlot](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.pairplot.html#seaborn.pairplot) let's us look at joint distributions for many variables at once.\n",
    "\n",
    "\n",
    "example_numeric_data = sample_data[[\"fixedAcidity\", \"volatileAcidity\",\n",
    "                                       \"citricAcid\", \"residualSugar\", \"Quality\"]]\n",
    "sb.pairplot(example_numeric_data, hue=\"Quality\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
